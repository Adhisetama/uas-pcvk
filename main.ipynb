{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Import Image Dataset**\n",
    "from file `ISIC_2017_Data_GroundTruth_Classification.csv`, get the value of `melanoma` corresponding for each `image_id` inside directory `PROJECT_Data` only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.1 Read the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>melanoma</th>\n",
       "      <th>seborrheic_keratosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0000002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0000004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  melanoma  seborrheic_keratosis\n",
       "0  ISIC_0000000       0.0                   0.0\n",
       "1  ISIC_0000001       0.0                   0.0\n",
       "2  ISIC_0000002       1.0                   0.0\n",
       "3  ISIC_0000003       0.0                   0.0\n",
       "4  ISIC_0000004       1.0                   0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('ISIC_2017_Data_GroundTruth_Classification.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = 'Z:/per-coolyeah-an/pengolahan-citra-dan-visi-komputer/Image_Processing/uas-pcvk/PROJECT_Data' # enih pathnya diganti\n",
    "\n",
    "ids = sorted(list(set([filename[:12] for filename in os.listdir(dataset_path)]))) # ngok\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.2 Data augmentation**\n",
    "- rotate 15 deg\n",
    "- rotate 345 deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def augment_images(dataset_path, image_id):\n",
    "    image = cv2.imread(f'{dataset_path}/{image_id}.jpg')\n",
    "    seg   = cv2.imread(f'{dataset_path}/{image_id}_segmentation.png')\n",
    "    output_path = f'{dataset_path}/../PROJECT_Data_Augmented/{image_id}'\n",
    "\n",
    "    def rotate_image(image, angle):\n",
    "        (h, w) = image.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        return cv2.warpAffine(image, matrix, (w, h))\n",
    "\n",
    "    rotated_image = rotate_image(image, 15)\n",
    "    rotated_seg   = rotate_image(seg, 15)\n",
    "    cv2.imwrite(f'{output_path}_r15.jpg', rotated_image)\n",
    "    cv2.imwrite(f'{output_path}_r15_segmentation.png', rotated_seg)\n",
    "    \n",
    "    rotated_image = rotate_image(image, 345)\n",
    "    rotated_seg   = rotate_image(seg, 345)\n",
    "    cv2.imwrite(f'{output_path}_r345.jpg', rotated_image)\n",
    "    cv2.imwrite(f'{output_path}_r345_segmentation.png', rotated_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_id in ids:\n",
    "    augment_images(dataset_path, image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.3 Extract Features and Save as CSV**\n",
    "calculate value of:\n",
    "1. symmetry\n",
    "2. reciprocal circularity (1/circularity)\n",
    "3. std deviation of RGB value\n",
    "   \n",
    "for each `image_id` inside `PROJECT_Data`, then save as `dataset.csv` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(dataset_path, image_id):\n",
    "    import numpy as np\n",
    "    \n",
    "    segmented = cv2.cvtColor(cv2.imread(f'{dataset_path}/{image_id}_segmentation.png'), cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.imread(f'{dataset_path}/{image_id}.jpg')\n",
    "\n",
    "    contours, _ = cv2.findContours(segmented, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    def calc_symmetry(segmented_image):\n",
    "        M = cv2.moments(segmented_image)\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        \n",
    "        top_left = segmented_image[:cY, :cX]\n",
    "        top_right = segmented_image[:cY, cX:]\n",
    "        bottom_left = segmented_image[cY:, :cX]\n",
    "        bottom_right = segmented_image[cY:, cX:]\n",
    "        \n",
    "        symmetry_score = (cv2.matchShapes(top_left, bottom_right, 1, 0.0) + \n",
    "                        cv2.matchShapes(top_right, bottom_left, 1, 0.0)) / 2\n",
    "        return { 'symmetry': symmetry_score }\n",
    "    \n",
    "    def calc_reciprocal_circularity(contour):\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        area = cv2.contourArea(contour)\n",
    "        return { '1/circularity': perimeter**2 / (4 * np.pi * area) }\n",
    "\n",
    "    def calc_std_color(image, segmented_image):\n",
    "        masked_image = cv2.bitwise_and(image, image, mask=segmented_image)\n",
    "        color_stddev = np.std(masked_image[segmented_image > 0], axis=0)\n",
    "        return { 'std_color': np.mean(color_stddev) }\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    # features.update(calc_hsv(image, segmented))\n",
    "    features.update(calc_symmetry(segmented))\n",
    "    features.update(calc_std_color(image, segmented))\n",
    "    features.update(calc_reciprocal_circularity(contour))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    'image_id': [],\n",
    "    'melanoma': []\n",
    "}\n",
    "\n",
    "for id in ids:\n",
    "    img_features = get_features(dataset_path, id)\n",
    "    img_features['image_id'] = id\n",
    "    img_features['melanoma'] = int(df[df['image_id'] == id].iloc[0]['melanoma'])\n",
    "    for feature_name in img_features:\n",
    "        if feature_name not in features:\n",
    "            features[feature_name] = []\n",
    "        features[feature_name].append(img_features[feature_name])\n",
    "\n",
    "fd = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>melanoma</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>std_color</th>\n",
       "      <th>1/circularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008072</td>\n",
       "      <td>39.369340</td>\n",
       "      <td>1.463696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>25.947679</td>\n",
       "      <td>1.716384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0000002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>27.861042</td>\n",
       "      <td>1.973328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>33.612228</td>\n",
       "      <td>1.465988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0000004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>34.173329</td>\n",
       "      <td>1.202164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  melanoma  symmetry  std_color  1/circularity\n",
       "0  ISIC_0000000         0  0.008072  39.369340       1.463696\n",
       "1  ISIC_0000001         0  0.001034  25.947679       1.716384\n",
       "2  ISIC_0000002         1  0.003091  27.861042       1.973328\n",
       "3  ISIC_0000003         0  0.003943  33.612228       1.465988\n",
       "4  ISIC_0000004         1  0.002960  34.173329       1.202164"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.to_csv('features.csv')\n",
    "fd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Train AI Classifier**\n",
    "using `dataset.csv`, build an AI Classifier to predict `melanoma` (either 1 or 0) using value of \n",
    "1. asymmetry\n",
    "2. border_irregularity\n",
    "3. color_irregularity\n",
    "4. differential_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.1 Split and augment the dataset**\n",
    "split into test and train dataset, then augment the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('features.csv')\n",
    "y = df['melanoma']\n",
    "\n",
    "df_train, df_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test  = df_test[['symmetry','std_color','1/circularity']]\n",
    "X_train = df_train[['symmetry','std_color','1/circularity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_path  = f'{dataset_path}/../PROJECT_Data_Augmented'\n",
    "aug_X_train = []\n",
    "aug_y_train = []\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    for aug in ['r15', 'r345']:\n",
    "        aug_features = get_features(aug_path, f'{row['image_id']}_{aug}')\n",
    "\n",
    "        aug_X_train.append(aug_features)\n",
    "        aug_y_train.append(row['melanoma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_X = pd.DataFrame.from_records(aug_X_train)\n",
    "temp_y = pd.Series(aug_y_train)\n",
    "\n",
    "X_train = pd.concat([X_train, temp_X], ignore_index=True)\n",
    "y_train = pd.concat([y_train, temp_y], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented train data length:  480\n"
     ]
    }
   ],
   "source": [
    "assert len(X_train) == len(y_train)\n",
    "print(\"augmented train data length: \", len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.1 Machine Learning**\n",
    "ML Model for classification used in this repository: \n",
    "- Logistic Regression\n",
    "- Support Vector Machine (SVM) Classifier\n",
    "- K-Nearest Neighbor (KNN) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70        21\n",
      "           1       0.67      0.74      0.70        19\n",
      "\n",
      "    accuracy                           0.70        40\n",
      "   macro avg       0.70      0.70      0.70        40\n",
      "weighted avg       0.70      0.70      0.70        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE: mending di run di google.colab, upload 'dataset.csv' yg udah diekstrak\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67        21\n",
      "           1       0.63      0.63      0.63        19\n",
      "\n",
      "    accuracy                           0.65        40\n",
      "   macro avg       0.65      0.65      0.65        40\n",
      "weighted avg       0.65      0.65      0.65        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68        21\n",
      "           1       0.65      0.68      0.67        19\n",
      "\n",
      "    accuracy                           0.68        40\n",
      "   macro avg       0.68      0.68      0.67        40\n",
      "weighted avg       0.68      0.68      0.68        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=20)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2 Neural Network (Multi Layer Percepteron)**\n",
    "a simple multi-layer percepteron (MLP):\n",
    "1. 3 dense layer, all using ReLU as activation function\n",
    "    - 16 percepteron\n",
    "    - 8 percepteron\n",
    "    - 8 percepteron\n",
    "2. a layer with 1 percepteron for classification, using sigmoid to squash the probability as activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5377 - loss: 0.7063 - val_accuracy: 0.5417 - val_loss: 0.6808\n",
      "Epoch 2/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5901 - loss: 0.6889 - val_accuracy: 0.6250 - val_loss: 0.6624\n",
      "Epoch 3/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6167 - loss: 0.6593 - val_accuracy: 0.6250 - val_loss: 0.6515\n",
      "Epoch 4/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6622 - loss: 0.6315 - val_accuracy: 0.6458 - val_loss: 0.6425\n",
      "Epoch 5/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6913 - loss: 0.6233 - val_accuracy: 0.6562 - val_loss: 0.6326\n",
      "Epoch 6/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6707 - loss: 0.6120 - val_accuracy: 0.6771 - val_loss: 0.6227\n",
      "Epoch 7/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6980 - loss: 0.5959 - val_accuracy: 0.6875 - val_loss: 0.6134\n",
      "Epoch 8/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7139 - loss: 0.5853 - val_accuracy: 0.6562 - val_loss: 0.6114\n",
      "Epoch 9/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6703 - loss: 0.6079 - val_accuracy: 0.6875 - val_loss: 0.6037\n",
      "Epoch 10/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6883 - loss: 0.5870 - val_accuracy: 0.6771 - val_loss: 0.6018\n",
      "Epoch 11/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7239 - loss: 0.5825 - val_accuracy: 0.6771 - val_loss: 0.6008\n",
      "Epoch 12/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7069 - loss: 0.5738 - val_accuracy: 0.6667 - val_loss: 0.5965\n",
      "Epoch 13/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6924 - loss: 0.5694 - val_accuracy: 0.6667 - val_loss: 0.5990\n",
      "Epoch 14/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7048 - loss: 0.5482 - val_accuracy: 0.6667 - val_loss: 0.5952\n",
      "Epoch 15/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6836 - loss: 0.5767 - val_accuracy: 0.6979 - val_loss: 0.5938\n",
      "Epoch 16/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6986 - loss: 0.5677 - val_accuracy: 0.6771 - val_loss: 0.5931\n",
      "Epoch 17/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6864 - loss: 0.5584 - val_accuracy: 0.6875 - val_loss: 0.5856\n",
      "Epoch 18/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6507 - loss: 0.6013 - val_accuracy: 0.6875 - val_loss: 0.5901\n",
      "Epoch 19/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7158 - loss: 0.5541 - val_accuracy: 0.6979 - val_loss: 0.5877\n",
      "Epoch 20/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7265 - loss: 0.5325 - val_accuracy: 0.6771 - val_loss: 0.5904\n",
      "Epoch 21/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7012 - loss: 0.5683 - val_accuracy: 0.6562 - val_loss: 0.5947\n",
      "Epoch 22/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7174 - loss: 0.5661 - val_accuracy: 0.7188 - val_loss: 0.5766\n",
      "Epoch 23/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7412 - loss: 0.5270 - val_accuracy: 0.6771 - val_loss: 0.5991\n",
      "Epoch 24/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7105 - loss: 0.5668 - val_accuracy: 0.7188 - val_loss: 0.5759\n",
      "Epoch 25/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6811 - loss: 0.5808 - val_accuracy: 0.6875 - val_loss: 0.5909\n",
      "Epoch 26/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7351 - loss: 0.5144 - val_accuracy: 0.6979 - val_loss: 0.5837\n",
      "Epoch 27/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6994 - loss: 0.5548 - val_accuracy: 0.6979 - val_loss: 0.5813\n",
      "Epoch 28/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6948 - loss: 0.5719 - val_accuracy: 0.7188 - val_loss: 0.5831\n",
      "Epoch 29/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7025 - loss: 0.5428 - val_accuracy: 0.7083 - val_loss: 0.5855\n",
      "Epoch 30/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6844 - loss: 0.5600 - val_accuracy: 0.6875 - val_loss: 0.5890\n",
      "Epoch 31/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7343 - loss: 0.5422 - val_accuracy: 0.6667 - val_loss: 0.5888\n",
      "Epoch 32/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7255 - loss: 0.5530 - val_accuracy: 0.7083 - val_loss: 0.5779\n",
      "Epoch 33/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7419 - loss: 0.5367 - val_accuracy: 0.7083 - val_loss: 0.5807\n",
      "Epoch 34/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7246 - loss: 0.5565 - val_accuracy: 0.6979 - val_loss: 0.5867\n",
      "Epoch 35/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7328 - loss: 0.5451 - val_accuracy: 0.6979 - val_loss: 0.5857\n",
      "Epoch 36/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7463 - loss: 0.5279 - val_accuracy: 0.6771 - val_loss: 0.5827\n",
      "Epoch 37/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7289 - loss: 0.5606 - val_accuracy: 0.7083 - val_loss: 0.5765\n",
      "Epoch 38/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6958 - loss: 0.5655 - val_accuracy: 0.6667 - val_loss: 0.5860\n",
      "Epoch 39/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7491 - loss: 0.5480 - val_accuracy: 0.6875 - val_loss: 0.5830\n",
      "Epoch 40/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7193 - loss: 0.5588 - val_accuracy: 0.7188 - val_loss: 0.5678\n",
      "Epoch 41/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7394 - loss: 0.5377 - val_accuracy: 0.7188 - val_loss: 0.5661\n",
      "Epoch 42/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6901 - loss: 0.5769 - val_accuracy: 0.7083 - val_loss: 0.5761\n",
      "Epoch 43/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6573 - loss: 0.5963 - val_accuracy: 0.7292 - val_loss: 0.5677\n",
      "Epoch 44/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6692 - loss: 0.5848 - val_accuracy: 0.7083 - val_loss: 0.5816\n",
      "Epoch 45/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7257 - loss: 0.5262 - val_accuracy: 0.7292 - val_loss: 0.5790\n",
      "Epoch 46/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6704 - loss: 0.5768 - val_accuracy: 0.7188 - val_loss: 0.5773\n",
      "Epoch 47/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7274 - loss: 0.5655 - val_accuracy: 0.7188 - val_loss: 0.5787\n",
      "Epoch 48/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7201 - loss: 0.5308 - val_accuracy: 0.6979 - val_loss: 0.5841\n",
      "Epoch 49/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7267 - loss: 0.5419 - val_accuracy: 0.7292 - val_loss: 0.5777\n",
      "Epoch 50/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7262 - loss: 0.5305 - val_accuracy: 0.7188 - val_loss: 0.5728\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6792 - loss: 0.6352 \n",
      "Test Accuracy: 0.675000011920929\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.52      0.63        21\n",
      "           1       0.62      0.84      0.71        19\n",
      "\n",
      "    accuracy                           0.68        40\n",
      "   macro avg       0.70      0.68      0.67        40\n",
      "weighted avg       0.70      0.68      0.67        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_ft = scaler.fit_transform(X_train)\n",
    "X_test_ft = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=X_train_ft.shape[1], activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss=BinaryCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_ft, y_train, epochs=50, batch_size=10, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_ft, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "y_pred_prob = model.predict(X_test_ft)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int) # probabilitas -> klasifikasi\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Summary**\n",
    "\n",
    "#### **3.1 Model Comparison**\n",
    "Comparison of all models shown in table below:\n",
    "\n",
    "| Model              | Precision | Accuracy | Recall  | F1 Score |\n",
    "|--------------------|-----------|----------|---------|----------|\n",
    "| Logistic Regression| 0.70      | 0.70     | 0.70    | 0.70     |\n",
    "| SVM                | 0.65      | 0.65     | 0.65    | 0.65     |\n",
    "| KNN                | 0.68      | 0.68     | 0.68    | 0.67     |\n",
    "| MLP                | 0.70      | 0.68     | 0.68    | 0.67     |\n",
    "\n",
    "#### **3.2 Feature Extractions**\n",
    "the feature needed to be extracted from image is\n",
    "1. `symmetry`\n",
    "    > Calculated by splitting the segmented image into four with the center is centroid of the lesions. then match the crossing region (top-left to down-right; top-right to down-left) with `cv2.matchShapes()`.\n",
    "2. `std_color`\n",
    "    > Done by calculating all standard deviation for every color channel (RGB) in the image then averaging the values. The image must be segmented and masked by the segmentation.\n",
    "3. `1/circularity`\n",
    "    > Done by calculating circularity (4pi*area)/perimeter^2 but the numerator and denominator is flipped\n",
    "\n",
    "#### **3.3 Model Training**\n",
    "The training of the model is done by splitting the dataset for train and testing with ratio of 0.2 (160 for training and 40 for testing). The 160 data for training then augmented by rotating it 15 degree and 345 degree, thus tripling the data into 480. All the features (`symmetry`, `std_color`, and `1/circularity`) in the train and test is calculated. Then the model is trained using the train data (including the augmented data).\n",
    "\n",
    "#### **3.4 Model Pipeline**\n",
    "the process to \"predict\" the skin lesion image with the model\n",
    "1. Image acquisition\n",
    "2. Skin lesions segmentation\n",
    "3. Calculate value of `symmetry`, `std_color`, and `1/circularity` using the original and segmented image as a mask\n",
    "4. Treat the values as feature vectors then predict with the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "classifier_model = {\n",
    "    'LogisticRegression': lr_model,\n",
    "    'SVM': svm_model,\n",
    "    'KNN': knn_model,\n",
    "    'MLP': model\n",
    "}\n",
    "\n",
    "for model_name in classifier_model:\n",
    "    joblib.dump(classifier_model[model_name], f'models/{model_name}.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Appendix**\n",
    "\n",
    "repository of the project: https://github.com/Adhisetama/uas-pcvk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
